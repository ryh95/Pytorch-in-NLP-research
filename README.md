# Pytorch in NLP research

This is a curated list of **papers** in **NLP** research using **Pytorch**.

## Papers Implemented by authors
`sen2vec` 

[Supervised Learning of Universal Sentence Representations from Natural Language Inference Data][1] (EMNLP 2017) 

`GCN` `graph`

[Semi-Supervised Classification with Graph Convolutional Networks][2] (ICLR 2017)

`Recurrent NN`

[Quasi-Recurrent Neural Networks][3] (ICLR 2017)

`QA`

[Reading Wikipedia to Answer Open-Domain Questions][4] (ACL 2017)

`Recurrent NN`

[Training RNNs as Fast as CNNs][5]

## Papers with Third-Party Implementations
`Recursive NN` `sen2vec`

[Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks][6] (ACL 2015)

`QA`

[Reading Wikipedia to Answer Open-Domain Questions][7] (ACL 2017)

`MT` `attention`

[Attention is All You Need][8]

`sen2vec`

[A Structured Self-attentive Sentence Embedding][9] (ICLR 2017)


[A Recurrent Latent Variable Model for Sequential Data][10] (NIPS 2015)

`Recurrent NN`

[Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting][11] (NIPS 2015)

`attention` `slot filling` `intent detection`

[Attention-Based Recurrent Neural Network Models for Joint Intent Detection and Slot Filling][12]


  [1]: https://github.com/facebookresearch/InferSent
  [2]: https://github.com/tkipf/pygcn
  [3]: https://github.com/salesforce/pytorch-qrnn
  [4]: https://github.com/facebookresearch/DrQA
  [5]: https://github.com/taolei87/sru
  [6]: https://github.com/dasguptar/treelstm.pytorch
  [7]: https://github.com/hitvoice/DrQA
  [8]: https://github.com/jadore801120/attention-is-all-you-need-pytorch
  [9]: https://github.com/ExplorerFreda/Structured-Self-Attentive-Sentence-Embedding
  [10]: https://github.com/emited/VariationalRecurrentNeuralNetwork
  [11]: https://github.com/automan000/Convolution_LSTM_pytorch
  [12]: https://github.com/DSKSD/RNN-for-Joint-NLU
